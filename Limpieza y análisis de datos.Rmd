---
title: "PRACTICA 2: LIMPIEZA Y VALIDACIÓN DE LOS DATOS"
author: "Gines Molina e Iñigo Alvarez"
date: "29/12/2020"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
  word_document: default
  pdf_document:
    highlight: zenburn
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r 1, message=FALSE, warning=FALSE}
#cargamos los paquetes que voy a usar
library(dplyr)
library(VIM)
library(ggplot2)
library(tidyverse)
library(scales)
```

# 1. Descripción del dataset

El dataset es un listado de ofertas de trabajo publicadas en Linkedin para ciencia de datos (térnimo "Data Scientist") que fue obtenido en la primera parte de esta práctica.

Consta de 6 archivos CSV con las ofertas encontradas a nivel de Escocia, Reino Unido, España, Mundo y remoto.

# 2. Integración y selección de los datos de interés a analizar

El primer paso es integrar los distintos archivos en un mismo dataset.

```{r}
Scotland <- read.csv("Scotland.csv", header=TRUE, sep=",", stringsAsFactors=FALSE)
Spain <- read.csv("Spain.csv", header=TRUE, sep=",", stringsAsFactors=FALSE)
UK <- read.csv("UK.csv", header=TRUE, sep=",", stringsAsFactors=FALSE)
WorldWide <- read.csv("WorldWide.csv", header=TRUE, sep=",", stringsAsFactors=FALSE)
Remote <- read.csv("Remote.csv", header=TRUE, sep=",", stringsAsFactors=FALSE)
Scotland$dataset <- "Scotland"
Spain$dataset <- "Spain"
UK$dataset <- "UK"
WorldWide$dataset <- "WorldWide"
Remote$dataset <- "Remote"
jobs <- rbind(Scotland, Spain, UK, WorldWide, Remote)
```

```{r}
str(jobs)
```

Quitamos la primera columna ya que no es más que un índice que no aporta ninguna información.

```{r}
jobs <- jobs[2:18]
```

# 3. Limpieza de los datos

Al haber integrado varios archivos de búsquedas de ámbitos territoriales que se solapan lo primero es eliminar las posibles duplicidades que podamos encontrar.

```{r}
sum(duplicated(jobs[1:5]))
```

Hay `r sum(duplicated(jobs[1:16]))` observaciones duplicadas así que las eliminamos.

```{r}
jobs <- jobs %>% 
  distinct(Job.ID, Company.Name, Location, .keep_all = TRUE)
```

# 3.1. Valores perdidos

Buscamos valores perdidos.
```{r}
sum(is.na(jobs))
sum(jobs=="")
sum(jobs=="None")
```

Suistituimos los valores en blanco por NA.

```{r}
jobs[jobs==""] <-- NA
jobs[jobs=="None"] <-- NA
```

Para corrgir los tipos de datos vamos a ver qué variables se podrían convertir a tipo factor.
```{r}
sapply(jobs, function(x) length(unique(x)))
```


Corregimos los tipos de los datos.
```{r}
jobs$Date <- as.Date(jobs$Date, format="%Y-%m-%d")
jobs$Solicitudes <- as.numeric(jobs$Solicitudes)
jobs$Visualizaciones <- as.numeric(jobs$Visualizaciones)
jobs$Level <- factor(jobs$Level, exclude = NULL)
jobs$Type <- factor(jobs$Type, exclude = NULL)
jobs$Empleados <- factor(jobs$Empleados, exclude = NULL)
jobs$Quick.Application <- factor(jobs$Quick.Application, exclude = NULL)
jobs$Recommended.Flavor <- factor(jobs$Recommended.Flavor, exclude = NULL)
jobs$dataset <- factor(jobs$dataset, exclude = NULL)
```

Nos quedamos solo con las ofertas publicadas a partir de
```{r}
all_jobs <- jobs
jobs <- jobs %>% 
  filter(Date >= "2020-10-01")
nrow(jobs)
```

Nos hemos quedado con `r nrow(jobs)` observaciones.

```{r}
summary(jobs)
```

Cambiamos los niveles para el tipo de jornada ya que la gran mayoría de ofertas son para jornada completa. Dejamos solo los niveles "Jornada completa" y "Otra jornada".

```{r}
Otra <- c("Contrato por obra", "Media jornada", "Otro", "Prácticas", "Temporal", "Voluntario")
jobs <- jobs %>%
  mutate(Type = fct_collapse(Type, "Otra jornada" = Otra))
```

Parece que los niveles de factor de Empleados no están ordenados de una forma coherente así que los ordenamos.
```{r}
levels(jobs$Empleados)
```

Los ordenamos.
```{r}
jobs$Empleados <- factor(jobs$Empleados, levels = c("2-10", "11-50", "51-200", "201-500", "501-1000", "1001-5000", "5001-10.000", "Más de 10.001"), exclude = NULL)
```


Mostramos la distribución de los valores perdidos.
```{r warning=FALSE}
sum(is.na(jobs))
aggr(jobs, numbers=TRUE, sortVars=TRUE, labels=names(jobs),
cex.axis=.7, gap=3, ylab=c("Missing data","Pattern"))
```

Tratamos los valores perdidos numéricos. 
```{r}
jobs <- jobs %>%
  group_by(Level, Quick.Application) %>%
    mutate(Solicitudes = ifelse(is.na(Solicitudes), median(Solicitudes, na.rm = TRUE), Solicitudes))
jobs <- jobs %>%
  group_by(Level, Quick.Application) %>%
    mutate(Visualizaciones = ifelse(is.na(Visualizaciones), median(Visualizaciones, na.rm = TRUE), Visualizaciones))
```

Comprobamos cómo quedan ahora los valores perdidos.
```{r warning=FALSE}
sum(is.na(jobs))
aggr(jobs, numbers=TRUE, sortVars=TRUE, labels=names(jobs),
cex.axis=.7, gap=3, ylab=c("Missing data","Pattern"))
```

```{r message=FALSE, warning=FALSE}
grid.arrange(
  qplot(Date, data=jobs)+ theme(axis.text.x = element_text(angle = 25)),
  qplot(Level, data=jobs)+ theme(axis.text.x = element_text(angle = 20, hjust=0.7, size = 7)),
  qplot(Type, data=jobs)+ theme(axis.text.x = element_text(angle = 20, hjust=1)),
  qplot(Solicitudes, data=jobs)+ theme(axis.text.x = element_text(angle = 25)),
  qplot(Empleados, data=jobs)+ theme(axis.text.x = element_text(angle = 30, hjust=0.7, size = 7)),
  qplot(Visualizaciones, data=jobs)+ theme(axis.text.x = element_text(angle = 25)),
  qplot(Recommended.Flavor, data=jobs)+ theme(axis.text.x = element_text(angle = 30, hjust=0.7, size = 7))
)
```

Hacemos un boxplot para cada una de las variables numéricas.
```{r}
ggplot(jobs, aes(x=Level, y=Solicitudes, color=Level)) + 
  ggtitle("Diagrama de cajas") + 
  scale_color_brewer(palette="Dark2") +
  geom_boxplot() +
  theme(legend.position = "null") +
  geom_jitter(width = 0.1)

ggplot(jobs, aes(x=Level, y=Visualizaciones, color=Level)) + 
  ggtitle("Diagrama de cajas") + 
  scale_color_brewer(palette="Dark2") +
  geom_boxplot() +
  theme(legend.position = "null") +
  geom_jitter(width = 0.1)
```

```{r}
tail(sort(boxplot.stats(jobs$Solicitudes)$out),5)
```

Voy a observar las tres ofertas de trabajo que superan las 3000 solicitudes.
```{r}
jobs[which(jobs$Solicitudes %in% tail(sort(boxplot.stats(jobs$Solicitudes)$out),3)),]
```

Aunque puede que sean valores razonables, a modo de ejemplo, eliminamos las 3 ofertas de trabajo que superan las 3000 solicitudes y mostramos cómo queda ahora el gráfico de los boxplots.
```{r}
jobs <- jobs[-which(jobs$Solicitudes %in% tail(sort(boxplot.stats(jobs$Solicitudes)$out),3)),]

ggplot(jobs, aes(x=Level, y=Solicitudes, color=Level)) + 
  ggtitle("Diagrama de cajas") + 
  scale_color_brewer(palette="Dark2") +
  geom_boxplot() +
  theme(legend.position = "null") +
  geom_jitter(width = 0.1)
```

# 4. Análisis de los datos.

## 4.3 Regresión logistica

```{r}
lgm <- glm(formula = Quick.Application ~ Level + Type + Solicitudes + Visualizaciones + Recommended.Flavor, family = binomial(link=logit), data = jobs)
summary(lgm)
```

$${logit}(p_i)=\ln\left(\frac{p_i}{1-p_i}\right) = `r round(lgm_$coefficients[1],2)` + `r round(lgm_$coefficients[2],2)`x_1 + `r round(lgm_$coefficients[3],2)`x_2 + `r round(lgm_$coefficients[4],2)`x_3 `r round(lgm_$coefficients[4],2)`x_4 `r round(lgm_$coefficients[4],2)`x_5 `r round(lgm_$coefficients[4],2)`x_3
6 `r round(lgm_$coefficients[4],2)`x_7 + `r round(lgm_$coefficients[4],2)`x_8 `r round(lgm_$coefficients[4],2)`x_9 `r round(lgm_$coefficients[4],2)`x_10 + `r round(lgm_$coefficients[4],2)`x_11 `r round(lgm_$coefficients[4],2)`x_12$$

```{r 3.3.3.1}
predicciones <- ifelse(test = lgm$fitted.values >= 0.5, yes = ">50%", no = "<50%")
matriz_confusion <- table(lgm$model$Quick.Application, predicciones,
                          dnn = c("observaciones", "predicciones"))
matriz_confusion
```

```{r}
library(vcd)
mosaic(matriz_confusion, shade = T, colorize = T,
       gp = gpar(fill = matrix(c("green3", "red2", "red2", "green3"), 2, 2)))
```
Podemos ver que hay `r matriz_confusion[3]` falsos positivos y `r matriz_confusion[2]` falsos negativos.
```{r}
sensibilidad <- label_percent(accuracy = 0.01)(matriz_confusion[4]/(matriz_confusion[4]+matriz_confusion[2]))
especificidad <- label_percent(accuracy = 0.01)(matriz_confusion[1]/(matriz_confusion[1]+matriz_confusion[3]))
cat("sensibilidad: ",  sensibilidad)
cat("\nespecificidad: ", especificidad)
```

La sensibilidad es del `r sensibilidad` y la especificidad del `r especificidad`.

```{r}
library(pROC)
prob=predict(lgm, newdata=jobs, type="response")
r=roc(response=jobs$Quick.Application, predictor=prob, data=data)
## Setting levels: control = 0, case = 1
## Setting direction: controls < cases
plot (r)
auc(r)
```


```{r}
head(jobs, 10)
```

```{r}
tail(jobs, 10)
```

